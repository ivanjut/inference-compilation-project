{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.infer\n",
    "import pyro.optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "smoke_test = ('CI' in os.environ)\n",
    "n_steps = 2 if smoke_test else 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Concept:\n",
    "    \n",
    "    def __init__(self, mult, params, max_num):\n",
    "        \"\"\"\n",
    "        :param mult: boolean flag that is True if concept is multiple, False if concept is range\n",
    "        :param params: list of params - [mult] if multiple concept, [start, end] if range concept\n",
    "        \"\"\"\n",
    "        self.mult = mult\n",
    "        self.params = params\n",
    "        self.max_num = max_num\n",
    "        self._numbers = self._populate_numbers()\n",
    "        self._probs = np.zeros(max_num + 1)\n",
    "        self._probs[self._numbers] = 1\n",
    "    \n",
    "    \n",
    "    def _populate_numbers(self):\n",
    "        \"\"\"\n",
    "        Fill in the number set for the concept\n",
    "        \"\"\"\n",
    "        if self.mult:\n",
    "            if (self.params[0] < 0) or (self.params[0] > self.max_num):\n",
    "                raise Exception('Invalid multiple for concept.')\n",
    "            \n",
    "            if not isinstance(self.params[0], int):\n",
    "                raise Exception('Multiple must be an integer.')\n",
    "                \n",
    "            numbers = np.arange(self.params[0], self.max_num + 1, self.params[0])\n",
    "            return numbers\n",
    "        else:\n",
    "            start, end = self.params[0], self.params[1]\n",
    "            \n",
    "            if (start < 0) or (end > self.max_num) or (start > end):\n",
    "                raise Exception('Invalid interval for concept.')\n",
    "            \n",
    "            if not (isinstance(start, int) and isinstance(end, int)):\n",
    "                raise Exception('Start and end must be integers.')\n",
    "                \n",
    "            numbers = np.arange(start, end+1)\n",
    "            return numbers\n",
    "        \n",
    "        \n",
    "    def sample(self, num_samples):\n",
    "        \"\"\"\n",
    "        Sample num_samples observations from the concept\n",
    "        \"\"\"\n",
    "        samples = []\n",
    "\n",
    "        for i in range(num_samples):\n",
    "            sample = random.choice(self.numbers)\n",
    "            samples.append(sample)\n",
    "\n",
    "        return samples\n",
    "    \n",
    "    \n",
    "    def __repr__(self):\n",
    "        if self.mult:\n",
    "            return 'Multiples of {}: {}'.format(self.params[0], self.numbers)\n",
    "        else:\n",
    "            return 'Range [{}, {}]: {}'.format(self.params[0], self.params[1], self.numbers)\n",
    "    \n",
    "    @property\n",
    "    def numbers(self):\n",
    "        return self._numbers\n",
    "\n",
    "    @property\n",
    "    def probs(self):\n",
    "        return self._probs\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self._numbers.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumberGame:\n",
    "    \n",
    "    def __init__(self, max_num, mult_range_start, mult_range_end, interval_range_length):\n",
    "        self.max_num = max_num\n",
    "        self.mult_range_start = mult_range_start\n",
    "        self.mult_range_end = mult_range_end\n",
    "        self.interval_range_length = interval_range_length\n",
    "        self.concepts, self.concept_probs = self.generate_all_concepts(20)\n",
    "        \n",
    "    \n",
    "    def _generate_multiple_concept(self, multiple):\n",
    "        \"\"\"\n",
    "        Generates a set of all multiples of multiple from [1,... , 100]\n",
    "        :param multiple: integer from [1, 100]\n",
    "        \"\"\"\n",
    "        mult_concept = Concept(True, [multiple], self.max_num)\n",
    "        return mult_concept\n",
    "    \n",
    "    \n",
    "    def _generate_range_concept(self, start, end):\n",
    "        \"\"\"\n",
    "        Generates a set of numbers from [start, ..., end] inclusive\n",
    "        \"\"\"\n",
    "        range_concept = Concept(False, [start, end], self.max_num)\n",
    "        return range_concept\n",
    "    \n",
    "    \n",
    "    def generate_all_concepts(self, mult_weight):\n",
    "        \"\"\"\n",
    "        Generate a set of all concepts as specified by parameters\n",
    "        :param mult_range_start: integer with smallest mult considered\n",
    "        :param mult_range_end: integer with largest mult considered\n",
    "        :param interval_range_length: length of ranges being considered\n",
    "        \"\"\"\n",
    "        concepts = []\n",
    "        \n",
    "        for multiple in range(self.mult_range_start, self.mult_range_end + 1):\n",
    "            mult_concept = self._generate_multiple_concept(multiple)\n",
    "            concepts.append(mult_concept)\n",
    "            \n",
    "        i = 1\n",
    "        while i + self.interval_range_length <= self.max_num:\n",
    "            range_concept = self._generate_range_concept(i, i + self.interval_range_length)\n",
    "            concepts.append(range_concept)\n",
    "            i += 1\n",
    "        \n",
    "        concept_probs = np.ones(len(concepts)) + np.concatenate((mult_weight * np.ones(self.mult_range_end - self.mult_range_start), np.zeros(len(concepts) - (self.mult_range_end - self.mult_range_start)))) \n",
    "\n",
    "        return (concepts, concept_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(max_num, mult_range_start, mult_range_end, interval_range_length, observations={\"obs1\": 0, \"obs2\": 0, \"obs3\": 0}):\n",
    "    number_game = NumberGame(max_num, mult_range_start, mult_range_end, interval_range_length)\n",
    "    \n",
    "    concepts = number_game.concepts\n",
    "    concept_probs = number_game.concept_probs\n",
    "    concept_index = int(pyro.sample(\"c\", dist.Categorical(torch.from_numpy(concept_probs))).numpy())\n",
    "    concept = concepts[concept_index]\n",
    "    \n",
    "    # define the likelihood\n",
    "    print(concept.probs)\n",
    "    likelihood = dist.Categorical(torch.from_numpy(concept.probs))\n",
    "    print(likelihood)\n",
    "    \n",
    "    # samples\n",
    "    y1 = pyro.sample(\"obs1\", likelihood, obs=observations[\"obs1\"])\n",
    "    y2 = pyro.sample(\"obs2\", likelihood, obs=observations[\"obs2\"])\n",
    "    y3 = pyro.sample(\"obs3\", likelihood, obs=observations[\"obs3\"])\n",
    "    \n",
    "    print(y1, y2, y3)\n",
    "    \n",
    "    return concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0.]\n",
      "Categorical(probs: torch.Size([101]))\n",
      "0 0 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Range [88, 98]: [88 89 90 91 92 93 94 95 96 97 98]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(100, 2, 10, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Guide(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Guide, self).__init__()\n",
    "        self.neural_net = nn.Sequential(\n",
    "            nn.Linear(3, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5, 1))\n",
    "\n",
    "    def forward(self, max_num, mult_range_start, mult_range_end, interval_range_length, observations={\"obs1\": 0, \"obs2\": 0, \"obs3\": 0}):\n",
    "        pyro.module(\"guide\", self)\n",
    "        obs1 = observations[\"obs1\"]\n",
    "        obs2 = observations[\"obs2\"]\n",
    "        obs3 = observations[\"obs3\"]\n",
    "        v = torch.cat((obs1.view(1, 1), obs2.view(1, 1), obs3.view(1, 1)), 1).float()\n",
    "        v = self.neural_net(v)\n",
    "\n",
    "        mean = v[0]\n",
    "        print(\"Mean: \", mean)\n",
    "        std = v[0].exp()\n",
    "        print(\"Std: \", std)\n",
    "        pyro.sample(\"z\", dist.Normal(mean, std))\n",
    "\n",
    "guide = Guide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = pyro.optim.Adam({'lr': 1e-3})\n",
    "csis = pyro.infer.CSIS(model, guide, optimiser, num_inference_samples=50)\n",
    "\n",
    "max_num = 100\n",
    "mult_range_start = 2\n",
    "mult_range_end = 10\n",
    "interval_range_length = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0.]\n",
      "Categorical(probs: torch.Size([101]))\n",
      "tensor(72) tensor(40) tensor(80)\n",
      "Mean:  tensor([-0.9981], grad_fn=<SelectBackward>)\n",
      "Std:  tensor([0.3686], grad_fn=<ExpBackward>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-e72faeda5ce3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mcsis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmult_range_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmult_range_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterval_range_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pyro/infer/csis.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \"\"\"\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mpoutine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mparam_capture\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_and_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         params = set(site[\"value\"].unconstrained()\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pyro/infer/csis.py\u001b[0m in \u001b[0;36mloss_and_grads\u001b[0;34m(self, grads, batch, *args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m                 guide_params = set(site[\"value\"].unconstrained()\n\u001b[1;32m    110\u001b[0m                                    for site in particle_param_capture.trace.nodes.values())\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0mguide_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparticle_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mguide_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide_param\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mguide_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguide_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                     \u001b[0mguide_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mguide_grad\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mguide_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mguide_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mguide_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    155\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[1;32m    156\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         inputs, allow_unused)\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior."
     ]
    }
   ],
   "source": [
    "for step in range(n_steps):\n",
    "    csis.step(max_num, mult_range_start, mult_range_end, interval_range_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
